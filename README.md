# PIDS Comparative Framework

<div align="center">

**A Unified Framework for Evaluating State-of-the-Art Provenance-based Intrusion Detection Systems**

[![Python 3.8+](https://img.shields.io/badge/python-3.8--3.10-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.12%2B-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

[Quick Start](#-quick-start) | [Installation](#-installation) | [Models](#-supported-models) | [Usage](#-usage) | [Troubleshooting](#-troubleshooting)

</div>

---

## ğŸ¯ Overview

The **PIDS Comparative Framework** is a production-ready platform that enables Security Operations Centers (SOC) to evaluate and compare state-of-the-art Provenance-based Intrusion Detection Systems (PIDS) on custom data.

### Primary Use Case

**Evaluate pretrained PIDS models on your custom SOC data** to determine which model performs best for your environment.

âœ… **Ready-to-Use**: Pretrained models included - no training required  
âœ… **Standalone**: All model implementations self-contained  
âœ… **Custom Data**: Works with your JSON-formatted system logs  
âœ… **Multi-Model**: Compare 5 state-of-the-art approaches simultaneously  
âœ… **CPU-First**: Runs on CPU by default, GPU optional  
ğŸ”„ **Advanced**: Retrain models on custom data (optional)

### What is Provenance-based Intrusion Detection?

Provenance graphs capture system-level information flows (processâ†’file, processâ†’network) to model normal behavior and detect anomalous activities indicative of cyber attacks. This framework integrates 5 state-of-the-art deep learning approaches for analyzing provenance data.

---

## ğŸ“Š Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Your SOC Data   â”‚ â”€â”€â”€> â”‚ Pretrained PIDS  â”‚ â”€â”€â”€> â”‚ Performance     â”‚
â”‚ (JSON Logs)     â”‚      â”‚ Models           â”‚      â”‚ Comparison      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                            â”‚
                                                            â–¼
                                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                    â”‚ Deploy Best     â”‚
                                                    â”‚ Model to SOC    â”‚
                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features

### ğŸ¯ Evaluation-First Design
- **Pretrained Models**: Use existing weights immediately - no training required
- **Quick Deployment**: Evaluate all models on your data in minutes
- **Performance Comparison**: Automatic comparison with statistical significance testing
- **One-Command Workflow**: `./scripts/run_evaluation.sh` handles everything

### ğŸ“Š Multi-Model Support
- **5 State-of-the-Art Models**: MAGIC, Kairos, Orthrus, ThreaTrace, Continuum_FL
- **Consistent Interface**: All models through unified `BasePIDSModel` API
- **Automatic Registration**: Dynamic model discovery via decorator pattern
- **Pretrained Weights**: Ready-to-use checkpoints for all models

### ğŸ”¬ Comprehensive Evaluation
- **Multiple Metrics**: AUROC, AUPRC, F1-Score, Precision, Recall, Detection Rate
- **Statistical Analysis**: Significance testing for model comparison
- **Rich Visualizations**: ROC curves, precision-recall curves, confusion matrices
- **Detailed Reports**: JSON and text formats with all metrics

### ğŸ”§ Production-Ready
- **CPU-First Design**: Runs on CPU by default (no GPU required)
- **GPU Support**: Automatic GPU detection and utilization when available
- **Large-Scale Data**: Handles 2GB+ JSON files with chunked loading
- **Checkpointing**: Save/resume training with early stopping (for retraining)
- **Comprehensive Logging**: Debug, info, warning, and error levels
- **Error Handling**: Graceful degradation and informative error messages

### ğŸ“¦ Easy to Use
- **YAML Configurations**: All settings in human-readable configs
- **One-Command Setup**: Automated environment and dependency installation
- **Streamlined Workflow**: Evaluation script handles all steps automatically
- **Comprehensive Documentation**: README, Setup.md, and EXTEND.md cover everything

### ğŸ”¬ Extensible Architecture (Advanced)
- **Modular Design**: Separate data, models, training, evaluation components
- **Plugin System**: Add new models with ~200 lines of code
- **Configurable**: Override any setting via YAML or command-line
- **Retraining Support**: Optional model training on custom datasets

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PIDS Comparative Framework                  â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Model Registry (Plugin System)                â”‚ â”‚
â”‚  â”‚  Auto-discovery via @register decorator                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  MAGIC   â”‚  â”‚ Kairos   â”‚  â”‚ Orthrus  â”‚  â”‚ThreaTraceâ”‚   â”‚
â”‚  â”‚ Wrapper  â”‚  â”‚ Wrapper  â”‚  â”‚ Wrapper  â”‚  â”‚ Wrapper  â”‚...â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â”‚       â”‚             â”‚              â”‚              â”‚          â”‚
â”‚  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      Standalone Model Implementations                 â”‚  â”‚
â”‚  â”‚  (No external dependencies)                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Data Pipeline                            â”‚  â”‚
â”‚  â”‚  JSON logs â†’ Graph â†’ Batching â†’ Evaluation           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‚ Directory Structure

```
PIDS_Comparative_Framework/
â”œâ”€â”€ README.md                       # This file - Framework overview
â”œâ”€â”€ Setup.md                        # Complete installation & usage guide
â”œâ”€â”€ EXTEND.md                       # Guide to add new models
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ environment.yml                 # Conda environment specification
â”‚
â”œâ”€â”€ models/                         # ğŸ§  Model implementations
â”‚   â”œâ”€â”€ base_model.py              # BasePIDSModel & ModelRegistry
â”‚   â”œâ”€â”€ __init__.py                # Auto-discovery of models
â”‚   â”‚
â”‚   â”œâ”€â”€ implementations/           # ğŸ“¦ Standalone implementations
â”‚   â”‚   â”œâ”€â”€ magic/                # MAGIC (Graph Autoencoder)
â”‚   â”‚   â”œâ”€â”€ kairos/               # Kairos (Temporal GNN)
â”‚   â”‚   â”œâ”€â”€ orthrus/              # Orthrus (Contrastive Learning)
â”‚   â”‚   â”œâ”€â”€ threatrace/           # ThreaTrace (Sketch-based)
â”‚   â”‚   â”œâ”€â”€ continuum_fl/         # Continuum_FL (Federated Learning)
â”‚   â”‚   â””â”€â”€ utils/                # Shared utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ magic_wrapper.py          # MAGIC â†’ BasePIDSModel adapter
â”‚   â”œâ”€â”€ kairos_wrapper.py         # Kairos adapter
â”‚   â”œâ”€â”€ orthrus_wrapper.py        # Orthrus adapter
â”‚   â”œâ”€â”€ threatrace_wrapper.py     # ThreaTrace adapter
â”‚   â””â”€â”€ continuum_fl_wrapper.py   # Continuum_FL adapter
â”‚
â”œâ”€â”€ data/                          # ğŸ“Š Dataset handling
â”‚   â””â”€â”€ dataset.py                # Base classes for datasets
â”‚
â”œâ”€â”€ experiments/                   # ğŸ§ª Experiment scripts
â”‚   â”œâ”€â”€ evaluate.py               # â­ Main evaluation script
â”‚   â”œâ”€â”€ train.py                  # Training script (advanced)
â”‚   â””â”€â”€ compare.py                # Multi-model comparison
â”‚
â”œâ”€â”€ utils/                         # ğŸ› ï¸ Framework utilities
â”‚   â”œâ”€â”€ common.py                 # Common utilities
â”‚   â””â”€â”€ metrics.py                # Evaluation metrics
â”‚
â”œâ”€â”€ scripts/                       # ğŸ“œ Setup & helper scripts
â”‚   â”œâ”€â”€ setup.sh                  # One-command environment setup
â”‚   â”œâ”€â”€ setup_models.py           # Download pretrained weights
â”‚   â”œâ”€â”€ preprocess_data.py        # Data preprocessing
â”‚   â”œâ”€â”€ run_evaluation.sh         # Complete evaluation workflow
â”‚   â”œâ”€â”€ verify_installation.py    # Installation verification
â”‚   â””â”€â”€ verify_implementation.py  # Framework verification
â”‚
â”œâ”€â”€ configs/                       # âš™ï¸ Configuration files
â”‚   â”œâ”€â”€ datasets/                 # Dataset configs
â”‚   â”œâ”€â”€ models/                   # Model configs
â”‚   â””â”€â”€ experiments/              # Experiment configs
â”‚
â”œâ”€â”€ checkpoints/                   # ğŸ’¾ Pretrained model weights
â”‚   â”œâ”€â”€ magic/                    # MAGIC checkpoints
â”‚   â”œâ”€â”€ kairos/                   # Kairos checkpoints
â”‚   â”œâ”€â”€ orthrus/                  # Orthrus checkpoints
â”‚   â”œâ”€â”€ threatrace/               # ThreaTrace checkpoints
â”‚   â””â”€â”€ continuum_fl/             # Continuum_FL checkpoints
â”‚
â”œâ”€â”€ data/                          # ğŸ“ Data directory
â”‚   â”œâ”€â”€ custom_soc/               # â† Your custom SOC data
â”‚   â”œâ”€â”€ cadets_e3/                # DARPA datasets (optional)
â”‚   â””â”€â”€ streamspot/               # StreamSpot dataset (optional)
â”‚
â””â”€â”€ results/                       # ğŸ“ˆ Evaluation results
    â””â”€â”€ evaluation_*/             # Timestamped result directories
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Conda** (Anaconda or Miniconda) - [Install Conda](https://docs.conda.io/en/latest/miniconda.html)
- **Python 3.8-3.10** (installed via Conda)
- **10GB disk space** (for dependencies and pretrained weights)
- **Git** (for downloading some model weights)

### Installation (5 minutes)

```bash
# Clone the repository
cd /path/to/PIDS_Files/PIDS_Comparative_Framework

# Run automated setup (creates environment, installs dependencies, downloads weights)
./scripts/setup.sh

# Activate environment
conda activate pids_framework

# Verify installation
python scripts/verify_installation.py
```

**Setup script does:**
1. âœ… Creates conda environment from `environment.yml`
2. âœ… Installs PyTorch 1.12.1 with CUDA 11.6 support
3. âœ… Installs DGL 1.0.0 (Deep Graph Library)
4. âœ… Installs PyTorch Geometric + extensions (torch-scatter, torch-sparse, torch-cluster)
5. âœ… Applies MKL threading fix automatically
6. âœ… Creates directory structure
7. âœ… Verifies installation

**Time:** 10-15 minutes (depending on download speed)

### Prepare Your Data

```bash
# 1. Place your JSON logs in custom_dataset/ directory
mkdir -p ../custom_dataset
cp /path/to/your/*.json ../custom_dataset/

# 2. Preprocess data (converts JSON â†’ graph format)
python scripts/preprocess_data.py \
    --input-dir ../custom_dataset \
    --output-dir data/custom_soc \
    --dataset-name custom_soc

# Output: custom_soc_graph.pkl, custom_soc_features.pt, custom_soc_metadata.json
```

### Evaluate Models

```bash
# Run evaluation on all models (automatic)
./scripts/run_evaluation.sh

# Or evaluate specific model
./scripts/run_evaluation.sh --model magic

# Or use preprocessed data directly
./scripts/run_evaluation.sh \
    --data-path data/custom_soc \
    --skip-preprocess
```

### View Results

```bash
# Check results directory
ls results/evaluation_*/

# View comparison report
cat results/evaluation_*/comparison_report.json

# View per-model results
cat results/evaluation_*/magic_evaluation.log
```

**That's it!** You've evaluated 5 PIDS models on your custom data.

---

## ğŸ§  Supported Models

### 1. MAGIC (Masked Graph Autoencoder)
- **Paper:** USENIX Security 2024
- **Architecture:** DGL-based graph autoencoder with masking
- **Approach:** Unsupervised learning via masked node/edge reconstruction
- **Weights:** âœ… Auto-downloaded from GitHub
- **Best For:** Large-scale provenance graphs, general-purpose APT detection

### 2. Kairos (Temporal Provenance Analysis)
- **Paper:** IEEE S&P 2024
- **Architecture:** Temporal GNN with database backend
- **Approach:** Time-aware graph neural network with historical context
- **Weights:** âš ï¸ Manual download from Google Drive required
- **Best For:** Long-term attack campaigns, temporal anomaly detection

### 3. Orthrus (Multi-Decoder Architecture)
- **Paper:** USENIX Security 2025
- **Architecture:** Contrastive learning with multiple decoders
- **Approach:** High-quality attribution through contrastive learning
- **Weights:** âœ… Auto-downloaded from GitHub or Zenodo
- **Best For:** Attack attribution, high-precision detection

### 4. ThreaTrace (Sketch-based Detection)
- **Paper:** IEEE TIFS 2022
- **Architecture:** Scalable sketch-based representation
- **Approach:** Efficient graph processing via sketching algorithms
- **Weights:** âœ… Auto-downloaded via git sparse-checkout (~500MB)
- **Best For:** Large-scale deployments, resource-constrained environments

### 5. Continuum_FL (Federated Learning)
- **Paper:** Federated Learning Conference
- **Architecture:** Federated learning with GAT and RNN
- **Approach:** Privacy-preserving distributed learning
- **Weights:** âœ… Auto-downloaded from GitHub
- **Best For:** Multi-site deployments, privacy-sensitive environments

---

## ğŸ“Š Supported Datasets

### DARPA TC (Transparent Computing)
- **Engagements:** E3, E5
- **Datasets:** CADETS, CLEARSCOPE, THEIA, TRACE
- **Events:** 100M+ system events
- **Format:** JSON (preprocessed available)

### StreamSpot
- **Source:** University of Illinois
- **Events:** 600+ application scenarios
- **Format:** Graph format
- **Use Case:** Anomaly detection benchmarks

### Custom SOC Data
- **Format:** JSON logs (Elastic/ELK or custom schema)
- **Events:** Process, file, network events
- **Size:** Supports 2GB+ files with chunked loading
- **Schema:** Flexible schema mapping

---

## âš™ï¸ Configuration

Models and datasets are configured via YAML files:

```yaml
# configs/models/magic.yaml
model:
  name: magic
  type: autoencoder
  architecture:
    encoder:
      hidden_dim: 128
      num_layers: 3
      dropout: 0.1

training:
  batch_size: 32
  learning_rate: 0.001
  epochs: 100

evaluation:
  batch_size: 64
  k_neighbors: 5
  detection_level: entity
```

Override settings:
```bash
python experiments/evaluate.py \
    --model magic \
    --config configs/models/magic_custom.yaml \
    --batch-size 16
```

---

## ğŸ§ª Usage Examples

### Basic Evaluation

```bash
# Evaluate all models
./scripts/run_evaluation.sh

# Evaluate specific model
./scripts/run_evaluation.sh --model magic
```

### Advanced Evaluation

```bash
# Direct evaluation with options
python experiments/evaluate.py \
    --model magic \
    --dataset custom_soc \
    --data-path data/custom_soc \
    --pretrained \
    --batch-size 16 \
    --detection-level entity \
    --k-neighbors 5 \
    --device 0 \
    --save-predictions \
    --output-dir results/my_eval
```

### Preprocessing Options

```bash
# Custom time window (1 hour)
python scripts/preprocess_data.py \
    --input-dir ../custom_dataset \
    --output-dir data/custom_soc \
    --dataset-name custom_soc \
    --time-window 3600

# Filter event types
python scripts/preprocess_data.py \
    --input-dir ../custom_dataset \
    --output-dir data/custom_soc \
    --dataset-name custom_soc \
    --event-types process file

# Large dataset optimization
python scripts/preprocess_data.py \
    --input-dir ../custom_dataset \
    --output-dir data/custom_soc \
    --dataset-name custom_soc \
    --chunk-size 50000 \
    --verbose
```

### Training (Advanced)

```bash
# Train MAGIC on custom data
python experiments/train.py \
    --model magic \
    --dataset custom_soc \
    --data-path data/custom_soc \
    --epochs 100 \
    --batch-size 32 \
    --learning-rate 0.001 \
    --output-dir results/training/magic

# Train with GPU
python experiments/train.py \
    --model magic \
    --device 0

# Resume training
python experiments/train.py \
    --model magic \
    --checkpoint checkpoints/magic/checkpoint-streamspot.pt \
    --resume
```

### Batch Processing

```bash
# Evaluate multiple datasets
for dataset in dataset1 dataset2 dataset3; do
    ./scripts/run_evaluation.sh \
        --data-path data/$dataset \
        --dataset $dataset \
        --output-dir results/${dataset}_evaluation
done
```

---

## ğŸ“ˆ Evaluation Metrics

### Detection Metrics
- **AUROC** (Area Under ROC Curve): Overall detection performance
- **AUPRC** (Area Under Precision-Recall Curve): Performance with class imbalance
- **F1-Score**: Harmonic mean of precision and recall
- **Precision**: True positive rate among positive predictions
- **Recall**: True positive rate among actual positives
- **Detection Rate**: Percentage of attacks detected

### Statistical Analysis
- **Significance Testing**: Paired t-tests for model comparison
- **Confidence Intervals**: 95% confidence intervals for metrics
- **Cross-Validation**: K-fold validation support

### Visualization
- **ROC Curves**: True positive rate vs false positive rate
- **Precision-Recall Curves**: Precision vs recall tradeoff
- **Confusion Matrices**: Classification breakdown
- **Feature Importance**: Top contributing features (model-dependent)

---

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. Conda environment not activated
```bash
Error: Conda environment 'pids_framework' is not activated!

Solution:
conda activate pids_framework
```

#### 2. PyTorch import fails
```bash
OSError: cannot allocate memory in static TLS block

Solution: MKL fix is automatic, but if it persists:
export MKL_THREADING_LAYER=GNU
python -c "import torch; print(torch.__version__)"
```

#### 3. Out of memory
```bash
RuntimeError: CUDA out of memory

Solution: Reduce batch size or use CPU
python experiments/evaluate.py --model magic --batch-size 4 --device -1
```

#### 4. Preprocessed data not found
```bash
Error: No preprocessed data found

Solution: Check filename
ls data/custom_soc/custom_soc_graph.pkl
# Or re-run preprocessing with correct dataset name
```

#### 5. Model checkpoint not found
```bash
Error: Checkpoint not found

Solution: Re-download checkpoints
python scripts/setup_models.py --all --force-download
```

**For detailed troubleshooting, see [Setup.md](Setup.md#troubleshooting)**

---

## ğŸ“– Documentation

- **[Setup.md](Setup.md)** - Complete installation and usage guide
- **[EXTEND.md](EXTEND.md)** - Guide to add new models
- **[SCRIPT_ANALYSIS.md](SCRIPT_ANALYSIS.md)** - Script analysis and maintenance guide

### Command Reference

| Script | Purpose | Documentation |
|--------|---------|---------------|
| `setup.sh` | Environment setup | [Setup.md](Setup.md#installation) |
| `setup_models.py` | Download weights | [Setup.md](Setup.md#model-specific-setup) |
| `preprocess_data.py` | Data preprocessing | [Setup.md](Setup.md#preparing-custom-data) |
| `run_evaluation.sh` | Evaluation workflow | [Setup.md](Setup.md#running-evaluation) |
| `verify_installation.py` | Installation checks | [Setup.md](Setup.md#verification) |
| `verify_implementation.py` | Framework verification | [Setup.md](Setup.md#verification) |

---

## ğŸ”¬ Extending the Framework

### Adding a New Model

The framework makes it easy to add new PIDS models:

```python
# models/your_model_wrapper.py
from models.base_model import BasePIDSModel, ModelRegistry

@ModelRegistry.register('your_model')
class YourModel(BasePIDSModel):
    def __init__(self, config):
        super().__init__(config)
        # Your implementation
    
    def forward(self, batch):
        # Forward pass
        pass
    
    def evaluate(self, dataloader, **kwargs):
        # Evaluation logic
        pass
```

**See [EXTEND.md](EXTEND.md) for complete guide** (~200 lines of code to add a model)

---

## ğŸ¤ Contributing

We welcome contributions! To contribute:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/your-feature`)
3. Commit your changes (`git commit -m 'Add some feature'`)
4. Push to the branch (`git push origin feature/your-feature`)
5. Open a Pull Request

### Contribution Areas

- ğŸ†• Add new PIDS models
- ğŸ“Š Add new datasets
- ğŸ§ª Add new evaluation metrics
- ğŸ“ Improve documentation
- ğŸ› Fix bugs
- âš¡ Performance optimizations

---

## ğŸ“š Citation

### Cite This Framework

```bibtex
@software{pids_comparative_framework_2025,
  title = {PIDS Comparative Framework: A Unified Platform for Provenance-based Intrusion Detection},
  author = {Your Name},
  year = {2025},
  url = {https://github.com/yourusername/PIDS_Comparative_Framework}
}
```

### Cite Individual Models

**MAGIC:**
```bibtex
@inproceedings{magic2024,
  title={MAGIC: Detecting Advanced Persistent Threats via Masked Graph Representation Learning},
  booktitle={USENIX Security},
  year={2024}
}
```

**Kairos:**
```bibtex
@inproceedings{kairos2024,
  title={Kairos: Practical Intrusion Detection and Investigation using Whole-system Provenance},
  booktitle={IEEE S&P},
  year={2024}
}
```

**Orthrus:**
```bibtex
@inproceedings{orthrus2025,
  title={Orthrus: High Quality Attribution in Provenance-based Intrusion Detection},
  booktitle={USENIX Security},
  year={2025}
}
```

**ThreaTrace:**
```bibtex
@article{threatrace2022,
  title={Enabling Refinable Cross-Host Attack Investigation with Efficient Data Flow Tagging and Tracking},
  journal={IEEE TIFS},
  year={2022}
}
```

**Continuum_FL:**
```bibtex
@inproceedings{continuum_fl,
  title={Federated Learning for Provenance-based Intrusion Detection},
  booktitle={Federated Learning Conference},
  year={2024}
}
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

### Third-Party Licenses

This framework integrates multiple PIDS models, each with their own licenses:
- **MAGIC**: Check [MAGIC repository](https://github.com/FDUDSDE/MAGIC)
- **Kairos**: Check [Kairos repository](https://github.com/ubc-provenance/kairos)
- **Orthrus**: Check [Orthrus repository](https://github.com/ubc-provenance/orthrus)
- **ThreaTrace**: Check [ThreaTrace repository](https://github.com/Provenance-IDS/threaTrace)
- **Continuum_FL**: Check [Continuum_FL repository](https://github.com/kamelferrahi/Continuum_FL)

---

## ğŸŒŸ Acknowledgments

This framework builds upon the excellent work of:

- **MAGIC Team** (FDUDSDE) - Masked graph autoencoder approach
- **Kairos Team** (UBC Provenance) - Temporal provenance analysis
- **Orthrus Team** (UBC Provenance) - High-quality attribution
- **ThreaTrace Team** - Scalable sketch-based detection
- **Continuum_FL Team** - Federated learning for PIDS

We thank the authors for making their models available and for advancing the field of provenance-based intrusion detection.

---

## ğŸ“ Support

### Getting Help

- **Documentation**: See [Setup.md](Setup.md) and [EXTEND.md](EXTEND.md)
- **Troubleshooting**: Check [Setup.md Troubleshooting](Setup.md#troubleshooting) section
- **Issues**: Open an issue on GitHub with detailed description
- **Examples**: See `configs/experiments/` for configuration templates

### Contact

For questions or issues:
- **GitHub Issues**: https://github.com/yourusername/PIDS_Comparative_Framework/issues
- **Email**: your.email@example.com

---

## ğŸ¯ Roadmap

### Current Version: 1.0.0 âœ…

- âœ… 5 integrated PIDS models
- âœ… Custom SOC data support
- âœ… DARPA TC dataset support
- âœ… Comprehensive evaluation metrics
- âœ… Model comparison framework
- âœ… CPU and GPU support
- âœ… Automated setup and workflow

### Planned Features (v1.1.0) ğŸ”„

- [ ] Web-based dashboard for real-time monitoring
- [ ] Automated hyperparameter optimization
- [ ] Ensemble model support
- [ ] Incremental learning for continuous deployment
- [ ] Integration with SIEM systems (Splunk, ELK, QRadar)
- [ ] REST API for model serving

### Future Enhancements (v2.0.0) ğŸš€

- [ ] Explainable AI features (attack path visualization)
- [ ] Active learning for label-efficient training
- [ ] Multi-host correlation analysis
- [ ] Streaming inference for real-time detection
- [ ] Attack scenario simulation
- [ ] Adversarial robustness testing

---

<div align="center">

**Made with â¤ï¸ for the Security Research Community**

If you find this framework useful, please â­ star the repository!

[â¬† Back to Top](#pids-comparative-framework)

</div>
